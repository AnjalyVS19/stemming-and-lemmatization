{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1cab44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\archa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a652817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather\n",
      "gathering\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('gathering',pos='v'))\n",
    "print(lemmatizer.lemmatize('gathering',pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8bdf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gather'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "stemmer.stem('gathering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5686c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "rock\n",
      "better\n",
      "greater\n",
      "greatest\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('running','v'))\n",
    "print(lemmatizer.lemmatize('rocks','v'))\n",
    "print(lemmatizer.lemmatize('better',pos='n'))\n",
    "print(lemmatizer.lemmatize('greater','v'))\n",
    "print(lemmatizer.lemmatize('greatest')) #By default pos is noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f03847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('run','v'))\n",
    "print(lemmatizer.lemmatize('ran','v'))\n",
    "print(lemmatizer.lemmatize('running','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566e7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "great\n",
      "great\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better','a'))\n",
    "print(lemmatizer.lemmatize('greater','a'))\n",
    "print(lemmatizer.lemmatize('greatest','a'))\n",
    "print(lemmatizer.lemmatize('best','a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc56ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greater\n",
      "greatest\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem('greater'))\n",
    "print(stemmer.stem('greatest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3b314",
   "metadata": {},
   "source": [
    "### Lemmitization of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19c7c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag #pos_tag to determine the pos of each word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1c8fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'were', 'mani', 'wizard', 'at', 'the', 'gather']\n",
      "['there', 'were', 'mani', 'wizard', 'at', 'the', 'gather']\n",
      "[['there', 'were', 'mani', 'wizard', 'at', 'the', 'gather'], ['there', 'were', 'mani', 'wizard', 'at', 'the', 'gather']]\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "corpus=[\n",
    "    \"i am gathering incredients for the sandwich\",\n",
    "    \"There were many wizards at the gathering\"\n",
    "]\n",
    "m=[]\n",
    "stemmer=PorterStemmer()\n",
    "for token in corpus:\n",
    "    l=[]\n",
    "    for token in word_tokenize(document):\n",
    "        l.append(stemmer.stem(token))\n",
    "    print(l)\n",
    "    m.append(l)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1f0c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'am', 'gather', 'incredi', 'for', 'the', 'sandwich'],\n",
       " ['there', 'were', 'mani', 'wizard', 'at', 'the', 'gather']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[stemmer.stem(token) for token in word_tokenize(document)] for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aea47197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\archa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d429bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('i', 'NN'), ('am', 'VBP'), ('gathering', 'VBG'), ('incredients', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('sandwich', 'NN')], [('There', 'EX'), ('were', 'VBD'), ('many', 'JJ'), ('wizards', 'NNS'), ('at', 'IN'), ('the', 'DT'), ('gathering', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "#lemmatization :- only lemmatizing verb and noun \n",
    "tagged_corpus=[pos_tag(word_tokenize(document))for document in corpus]\n",
    "print(tagged_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "532626d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "V\n",
      "V\n",
      "N\n",
      "N\n",
      "V\n",
      "N\n",
      "N\n",
      "[['i', 'be', 'gather', 'incredients', 'for', 'the', 'sandwich'], ['There', 'be', 'many', 'wizard', 'at', 'the', 'gathering']]\n"
     ]
    }
   ],
   "source": [
    "word_net=['v','n']\n",
    "def lemmatise(token,tag):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    if tag[0].lower() in word_net:\n",
    "        print(tag[0])\n",
    "        return lemmatizer.lemmatize(token,tag[0].lower())\n",
    "    return token\n",
    "m=[]\n",
    "for document in tagged_corpus:\n",
    "    k=[]\n",
    "    for token,tag in document:\n",
    "        k.append(lemmatise(token,tag))\n",
    "    m.append(k)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9822f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "V\n",
      "V\n",
      "N\n",
      "N\n",
      "V\n",
      "N\n",
      "N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['i', 'be', 'gather', 'incredients', 'for', 'the', 'sandwich'],\n",
       " ['There', 'be', 'many', 'wizard', 'at', 'the', 'gathering']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[lemmatise(token,tag) for token,tag in document]for document in tagged_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2b133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
